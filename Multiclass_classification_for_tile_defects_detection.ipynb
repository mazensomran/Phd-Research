{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a_V5X6zCdASxV_RmKyGVyGgzz4Pk11r8",
      "authorship_tag": "ABX9TyPd+ebVZJBljHmxbiL0uBcO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDl8YOfkOHy1"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import sys\n",
        "import cv2\n",
        "import os\n",
        "from scipy import ndimage as nd\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/train/\"\n",
        "img_path1 = \"/content/drive/MyDrive/test/\"\n",
        "\n",
        "X_train =[]\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []"
      ],
      "metadata": {
        "id": "8j4Xg6kfOS1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next three cells are preparing train and test dataset for multiclass classification"
      ],
      "metadata": {
        "id": "ItGlSGMi6O8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image in os.listdir(img_path):  # iterate through each file\n",
        "    if image.split('.')[0][:3] == 'cra':\n",
        "      y_train.append(1)\n",
        "    elif image.split('.')[0][:3] == 'oil':\n",
        "      y_train.append(2)\n",
        "    elif image.split('.')[0][:3] == 'glu':\n",
        "      y_train.append(3)\n",
        "    elif image.split('.')[0][:3] == 'gra':\n",
        "      y_train.append(4)\n",
        "    elif image.split('.')[0][:3] == 'rou':\n",
        "      y_train.append(5)\n",
        "    else:\n",
        "        y_train.append(0)\n",
        "    input_img = cv2.imread(img_path + image)  # Read images\n",
        "    img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (105, 105))\n",
        "    X_train.append(img)"
      ],
      "metadata": {
        "id": "lAdmMQWEOlng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in os.listdir(img_path1):  # iterate through each file\n",
        "\n",
        "    if image.split('.')[0][:3] == 'cra':\n",
        "      y_test.append(1)\n",
        "    elif image.split('.')[0][:3] == 'oil':\n",
        "      y_test.append(2)\n",
        "    elif image.split('.')[0][:3] == 'glu':\n",
        "      y_test.append(3)\n",
        "    elif image.split('.')[0][:3] == 'gra':\n",
        "      y_test.append(4)\n",
        "    elif image.split('.')[0][:3] == 'rou':\n",
        "      y_test.append(5)\n",
        "    else:\n",
        "        y_test.append(0)\n",
        "\n",
        "    input_img = cv2.imread(img_path1 + image)  # Read images\n",
        "    img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (105, 105))\n",
        "    X_test.append(img)"
      ],
      "metadata": {
        "id": "f_5F07ycOt9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= np.array(X_train)\n",
        "y_train= np.array(y_train)\n",
        "X_test= np.array(X_test)\n",
        "y_test= np.array(y_test)"
      ],
      "metadata": {
        "id": "wp0aCl9zOxJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next four cells are preparing train and test dataset for binary classification"
      ],
      "metadata": {
        "id": "XDN6ED2H6S4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1 =[]\n",
        "y_train1 = []\n",
        "X_test1 = []\n",
        "y_test1 = []"
      ],
      "metadata": {
        "id": "E8QkyaVV5Cbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in os.listdir(img_path):  # iterate through each file\n",
        "    if image.split('.')[0][:3] in ['cra','oil','glu','gra','rou']:\n",
        "      y_train1.append(1)\n",
        "    else:\n",
        "      y_train1.append(0)\n",
        "    input_img = cv2.imread(img_path + image)  # Read images\n",
        "    img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (105, 105))\n",
        "    X_train1.append(img)"
      ],
      "metadata": {
        "id": "xVAyX4Xn4l-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in os.listdir(img_path1):  # iterate through each file\n",
        "    if image.split('.')[0][:3] in ['cra','oil','glu','gra','rou']:\n",
        "      y_test1.append(1)\n",
        "    else:\n",
        "      y_test1.append(0)\n",
        "    input_img = cv2.imread(img_path1 + image)  # Read images\n",
        "    img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (105, 105))\n",
        "    X_test1.append(img)"
      ],
      "metadata": {
        "id": "thspYNDX5L9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1= np.array(X_train1)\n",
        "y_train1= np.array(y_train1)\n",
        "X_test1= np.array(X_test1)\n",
        "y_test1= np.array(y_test1)"
      ],
      "metadata": {
        "id": "JMLCM_Du5cdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_test1\n",
        "          ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfEXCDLeu62L",
        "outputId": "ac2ed4f1-135e-44a9-92ec-f766e189788a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input shape is (n, x, y, c) - number of images, x, y, and channels\n",
        "def feature_extractor(dataset):\n",
        "    x_train = dataset\n",
        "    image_dataset = pd.DataFrame()\n",
        "    for image in range(x_train.shape[0]):  #iterate through each file\n",
        "        #print(image)\n",
        "\n",
        "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
        "        #Reset dataframe to blank after each loop.\n",
        "\n",
        "        input_img = x_train[image, :,:]\n",
        "        img = input_img\n",
        "    ################################################################\n",
        "    #START ADDING DATA TO THE DATAFRAME\n",
        "    #Add feature extractors, e.g. edge detection, smoothing, etc.\n",
        "\n",
        "         # FEATURE 1 - Pixel values\n",
        "\n",
        "        #Add pixel values to the data frame\n",
        "        pixel_values = img.reshape(-1)/255.0\n",
        "        df['Pixel_Value'] = pixel_values  #Pixel value itself as a feature\n",
        "        #df['Image_Name'] = image   #Capture image name as we read multiple images\n",
        "\n",
        "        # ROBERTS EDGE\n",
        "        edge_roberts = roberts(img)\n",
        "        edge_roberts1 = edge_roberts.reshape(-1)\n",
        "        df['Roberts'] = edge_roberts1\n",
        "\n",
        "        # SOBEL\n",
        "        edge_sobel = sobel(img)\n",
        "        edge_sobel1 = edge_sobel.reshape(-1)\n",
        "        df['Sobel'] = edge_sobel1\n",
        "\n",
        "        # SCHARR\n",
        "        edge_scharr = scharr(img)\n",
        "        edge_scharr1 = edge_scharr.reshape(-1)\n",
        "        df['Scharr'] = edge_scharr1\n",
        "\n",
        "        # PREWITT\n",
        "        edge_prewitt = prewitt(img)\n",
        "        edge_prewitt1 = edge_prewitt.reshape(-1)\n",
        "        df['Prewitt'] = edge_prewitt1\n",
        "\n",
        "        # CANNY EDGE\n",
        "        img1 = np.uint8(img)\n",
        "        edges = cv2.Canny(img1, 100, 200)  # Image, min and max values\n",
        "        edges1 = edges.reshape(-1)/255.0\n",
        "        df['Canny_Edge'] = edges1\n",
        "\n",
        "        # GAUSSIAN with sigma=3\n",
        "        gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
        "        gaussian_img1 = gaussian_img.reshape(-1)/255.0\n",
        "        df['Gaussian3'] = gaussian_img1\n",
        "\n",
        "        median_img = nd.median_filter(img, size=3)\n",
        "        median_img1 = median_img.reshape(-1)/255.0\n",
        "        df['Median3'] = median_img1\n",
        "        #Append features from current image to the dataset\n",
        "        image_dataset = pd.concat([image_dataset,df])\n",
        "\n",
        "    return image_dataset"
      ],
      "metadata": {
        "id": "KfXUS02AQbFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_features = feature_extractor(X_train1)"
      ],
      "metadata": {
        "id": "epvo5vkoQldo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = image_features.shape[1]\n",
        "image_features = np.expand_dims(image_features, axis=0)\n",
        "x_Train1 = np.reshape(image_features, (X_train1.shape[0], -1))  #Reshape to #images, features"
      ],
      "metadata": {
        "id": "m19TKmpNQmDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract features from test data and reshape, just like training data\n",
        "test_features = feature_extractor(X_test1)\n",
        "test_features = np.expand_dims(test_features, axis=0)\n",
        "X_Test1 = np.reshape(test_features, (X_test1.shape[0], -1))\n"
      ],
      "metadata": {
        "id": "ZolrhBjyQ48-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model = RandomForestClassifier()\n",
        "#Training the model and estimate training time\n",
        "RF_model.fit(x_Train1, y_train1)\n",
        "\n",
        "#Predict on test\n",
        "test_prediction = RF_model.predict(X_Test1)\n",
        "\n",
        "##Check model metrics on test dataset.\n",
        "print (\"Accuracy RF_model = \", metrics.accuracy_score(y_test1, test_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SP8MDV_Q_sH",
        "outputId": "8b424429-bafa-49e2-830d-f57fd6d2be4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy RF_model =  0.5263157894736842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_samole_features (image):\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.resize(img, (105, 105))\n",
        "  img = np.array(img)\n",
        "  df = pd.DataFrame()\n",
        "  df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
        "        #Reset dataframe to blank after each loop.\n",
        "\n",
        "  # FEATURE 1 - Pixel values\n",
        "\n",
        "  #Add pixel values to the data frame\n",
        "  pixel_values = img.reshape(-1)/255.0\n",
        "  df['Pixel_Value'] = pixel_values  #Pixel value itself as a feature\n",
        "  #df['Image_Name'] = image   #Capture image name as we read multiple images\n",
        "\n",
        "  # ROBERTS EDGE\n",
        "  edge_roberts = roberts(img)\n",
        "  edge_roberts1 = edge_roberts.reshape(-1)\n",
        "  df['Roberts'] = edge_roberts1\n",
        "\n",
        "        # SOBEL\n",
        "  edge_sobel = sobel(img)\n",
        "  edge_sobel1 = edge_sobel.reshape(-1)\n",
        "  df['Sobel'] = edge_sobel1\n",
        "\n",
        "  # SCHARR\n",
        "  edge_scharr = scharr(img)\n",
        "  edge_scharr1 = edge_scharr.reshape(-1)\n",
        "  df['Scharr'] = edge_scharr1\n",
        "\n",
        "  # PREWITT\n",
        "  edge_prewitt = prewitt(img)\n",
        "  edge_prewitt1 = edge_prewitt.reshape(-1)\n",
        "  df['Prewitt'] = edge_prewitt1\n",
        "\n",
        "        # CANNY EDGE\n",
        "  img1 = np.uint8(img)\n",
        "  edges = cv2.Canny(img1, 100, 200)  # Image, min and max values\n",
        "  edges1 = edges.reshape(-1)/255.0\n",
        "  df['Canny_Edge'] = edges1\n",
        "\n",
        "        # GAUSSIAN with sigma=3\n",
        "  gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
        "  gaussian_img1 = gaussian_img.reshape(-1)/255.0\n",
        "  df['Gaussian3'] = gaussian_img1\n",
        "\n",
        "  median_img = nd.median_filter(img, size=3)\n",
        "  median_img1 = median_img.reshape(-1)/255.0\n",
        "  df['Median3'] = median_img1\n",
        "        #Append features from current image to the dataset\n",
        "  df = np.expand_dims(df, axis=0)\n",
        "  Test = np.reshape(df, (1, -1))\n",
        "\n",
        "  return Test\n",
        "\n"
      ],
      "metadata": {
        "id": "mvZplJak0tmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = one_samole_features (\"/content/drive/MyDrive/augmented_tile_test1/oil17.png\")\n",
        "res = RF_model.predict(test)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no_FXCwZxf1L",
        "outputId": "3c6896ef-8285-48db-bc43-b94f3ea9199c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test,test_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tt-DtnMwGsV",
        "outputId": "0233a0b4-02af-4cbf-e7d8-ff4eee814947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.69       100\n",
            "           1       0.00      0.00      0.00        20\n",
            "           2       0.00      0.00      0.00        25\n",
            "           3       0.00      0.00      0.00        15\n",
            "           4       0.00      0.00      0.00        15\n",
            "           5       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.53       190\n",
            "   macro avg       0.09      0.17      0.11       190\n",
            "weighted avg       0.28      0.53      0.36       190\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "SVM_model = svm.SVC(kernel='poly')\n",
        "#Training the model and estimate training time\n",
        "SVM_model.fit(x_Train1, y_train1)\n",
        "\n",
        "#Predict on test\n",
        "test_prediction = SVM_model.predict(X_Test1)\n",
        "\n",
        "##Check model metrics on test dataset.\n",
        "print (\"Accuracy SVM_model = \", metrics.accuracy_score(y_test1, test_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBdhlhiBRW9Z",
        "outputId": "a3e046be-dee8-472b-b1e9-1be267266d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy SVM_model =  0.5263157894736842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test1,test_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRIQmt6-S2-w",
        "outputId": "40960738-7e4b-4687-8534-52a910dd4d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.69       100\n",
            "           1       0.00      0.00      0.00        90\n",
            "\n",
            "    accuracy                           0.53       190\n",
            "   macro avg       0.26      0.50      0.34       190\n",
            "weighted avg       0.28      0.53      0.36       190\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}